{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34674,"sourceType":"datasetVersion","datasetId":26069}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:09:04.784789Z","iopub.execute_input":"2025-07-20T07:09:04.785188Z","iopub.status.idle":"2025-07-20T07:09:05.255176Z","shell.execute_reply.started":"2025-07-20T07:09:04.785162Z","shell.execute_reply":"2025-07-20T07:09:05.254166Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# CQ500Dataset (torch.utils.data.Dataset) class\nimport cv2\nimport numpy as np\nfrom pandas import DataFrame\nimport torch\nimport pydicom\nimport pydicom.dataset\nfrom pydicom.pixel_data_handlers.util import _apply_modality_lut\n\n\n# Class\nclass CQ500Dataset(torch.utils.data.Dataset):\n    \"\"\"\n    Connects `cq500ct_manifest.parquet` and `label.csv` and turns into Pytorch `tensors`.\n    Returns x (shape), y (torch tensor float32) could be used as tran_ds.\n    \"\"\"\n\n    def __init__(\n        self, manifest_df: DataFrame, labels_df: DataFrame, transform=None\n    ) -> None:\n        \"\"\"\n        manifest_df is the `parquet` file created from the whole dataset.\n        labels_df is the `csv` file created from `reads.csv`.\n        \"\"\"\n        self.mf = manifest_df\n        self.lbl = labels_df.set_index(\"name\")  # name as index\n        # self.ids become the master ids list, serving the pipeline.\n        # find the unique and pixel + labels scans\n        self.ids = self.lbl.index.intersection(self.mf[\"name\"].unique())\n        self.tf = transform\n\n    def __len__(self) -> int:\n        \"\"\"Report the number of studies (not slices) as `int`.\"\"\"\n        return len(self.ids)\n\n    def __getitem__(self, idx) -> tuple:\n        study = self.ids[idx]  ## Pick a study (not slices)\n        df = self.mf[\n            self.mf[\"name\"] == study\n        ]  ## All the rows belonging to this study (chosen index) -> single patient row in manifest\n        sid = df[\"series_uid\"].iloc[0]  ## Pick one series #! ???\n        slices = df[\n            df[\"series_uid\"] == sid\n        ]  ## All slices (rows) for the selected series within the study\n        volume = [to_windowed_tensor(pydicom.dcmread(p)) for p in slices[\"path\"]]\n        x = torch.stack(\n            volume\n        )  ## Stack per-slice tensors into a 4D batch [num_slice, num_chan, h, w]\n        y = self.lbl.loc[\n            study, \"ICH-majority\"\n        ]  ## Target scalar label (soft or majority)\n        if self.tf:\n            x = self.tf(x)\n        return x, torch.tensor(y, dtype=torch.float32)\n\n\n# Helper\n# DICOM to Tensor\ndef to_windowed_tensor(\n    ds: pydicom.dataset.FileDataset,\n    windows: list[tuple[int, int]] = None,\n    out_size: tuple[int, int] = None,\n    dtype: torch.dtype = torch.float32,\n) -> torch.tensor:\n    \"\"\"\n    Helper: convert one DICOM slice into a torch.Tensor [C x H x W]\n    ds\t\t\t= single CQ500 DICOM slice.\n    windows\t\t= CT window to apply. Each tuple becomes one output channel.\n                    Default = Brain, Subdural, Bone.\n    out_size\t= (H, W) to resize the slice.\n    dtype\t\t= final tensor percision (float32 recommended).\n\n    Returns\t\t= torch.tensor (shape = C x H x W with normalized values)\n    \"\"\"\n    ## Handle None args\n    if windows is None:\n        windows = [(40, 80), (80, 200), (600, 2800)]\n    if out_size is None:\n        out_size = (256, 256)\n\n    ## Raw values > Hounsfield units (HU)\n    hu: np.ndarray = _apply_modality_lut(ds.pixel_array, ds).astype(np.int16)\n    if out_size is not None and hu.shape != out_size:\n        hu = cv2.resize(hu, out_size[::-1], interpolation=cv2.INTER_LINEAR)\n\n    ## Window / Level > 0-1 float per channel\n    ## 3 channels to feed into model\n    chans: list[np.ndarray] = []\n    for level, width in windows:\n        level: int\n        width: int\n        lower: int = level - (width // 2)\n        upper: int = level + (width // 2)\n        img_clipped: np.ndarray = np.clip(hu, lower, upper)\n        img_norm: np.ndarray = (img_clipped - lower) / float(width)  # 0 - 1\n        chans.append(img_norm.astype(np.float32))\n\n    ## Stack and convert to tensor\n    arr: np.ndarray = np.stack(chans, axis=0)  # C x H x W\n    tensor: torch.Tensor = torch.from_numpy(arr).type(dtype)\n\n    return tensor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:09:19.588185Z","iopub.execute_input":"2025-07-20T07:09:19.590292Z","iopub.status.idle":"2025-07-20T07:09:22.640029Z","shell.execute_reply.started":"2025-07-20T07:09:19.590220Z","shell.execute_reply":"2025-07-20T07:09:22.639155Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"## Load compact_reads and manifest. Load and read data for testing.\nimport os\nimport numpy as np\nimport pandas as pd\n\npq = pd.read_parquet(\"cq500ct_manifest.parquet\")\npq[\"name\"] = pq[\"name\"].astype(str)\n\ncompact_reads = pd.read_csv(\"compact_reads.csv\")\n\nds = CQ500Dataset(manifest_df=pq, labels_df=compact_reads, transform=None)\nprint(f\"Studies available: {len(ds)}\")\t# available studies\n\nx, y = ds[0]\nprint(\"tensor shape: \", x.shape)\nprint(\"label - ICH: \", y.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:09:25.642225Z","iopub.execute_input":"2025-07-20T07:09:25.643906Z","iopub.status.idle":"2025-07-20T07:09:26.474697Z","shell.execute_reply.started":"2025-07-20T07:09:25.643849Z","shell.execute_reply":"2025-07-20T07:09:26.473419Z"}},"outputs":[{"name":"stdout","text":"Studies available: 473\ntensor shape:  torch.Size([32, 3, 256, 256])\nlabel - ICH:  1.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"## Metadata from manifest + compact_reads.\nmetadata_df = pq.merge(\n    compact_reads[['name', 'ICH-majority']],\n    on='name',\n    how='left',\n    validate='many_to_one',\n    indicator=True\n)\nmetadata_df.to_parquet(\"cq500ct_metadata.parquet\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:09:45.416136Z","iopub.execute_input":"2025-07-20T07:09:45.416510Z","iopub.status.idle":"2025-07-20T07:09:45.682292Z","shell.execute_reply.started":"2025-07-20T07:09:45.416483Z","shell.execute_reply":"2025-07-20T07:09:45.681166Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"## Shuffle split to prevent leakage. Split by patient \"name\"\n## CHANGE THIS TO B1 CATEGORY SPLIT ONLY\n\nfrom sklearn.model_selection import GroupShuffleSplit\nsplitter = GroupShuffleSplit(\n    test_size=0.2,\n    n_splits=1,\n    random_state=42\n)\ntrain_idx, val_idx = next(splitter.split(X=metadata_df, y=metadata_df[\"ICH-majority\"], groups=metadata_df[\"name\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:09:50.920643Z","iopub.execute_input":"2025-07-20T07:09:50.921059Z","iopub.status.idle":"2025-07-20T07:09:51.785075Z","shell.execute_reply.started":"2025-07-20T07:09:50.921031Z","shell.execute_reply":"2025-07-20T07:09:51.783992Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"## Check leakage between train and validation indecies\n# assert set(metadata_df.iloc[train_idx].name).isdisjoint(metadata_df.iloc[val_idx].name), \"Leakage\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Create dataframes from indecies (train and val)\ndf = metadata_df.rename(columns={\"ICH-majority\": \"ICH_majority\"})\n# df.iloc[train_idx].ICH_majority.mean()\n\ntrain_df = (df.iloc[train_idx][\"name\"].unique())\n\nval_df = (df.iloc[val_idx][\"name\"].unique())\n\ntrain_df = sorted(train_df)\nval_df = sorted(val_df)\n\nassert set(train_df).isdisjoint(val_df), \"Leakage detected!\"\nprint(f\"{len(train_df)=}, {len(val_df)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:20:14.037437Z","iopub.execute_input":"2025-07-20T07:20:14.037943Z","iopub.status.idle":"2025-07-20T07:20:14.099726Z","shell.execute_reply.started":"2025-07-20T07:20:14.037915Z","shell.execute_reply":"2025-07-20T07:20:14.098595Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"## Save dataframes into text files (train and val)\npd.Series(train_df).to_csv(\"train_patients.txt\", index=False, header=False)\npd.Series(val_df).to_csv(\"val_patients.txt\", index=False, header=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:22:50.689938Z","iopub.execute_input":"2025-07-20T07:22:50.690298Z","iopub.status.idle":"2025-07-20T07:22:50.699671Z","shell.execute_reply.started":"2025-07-20T07:22:50.690272Z","shell.execute_reply":"2025-07-20T07:22:50.698627Z"}},"outputs":[],"execution_count":18}]}